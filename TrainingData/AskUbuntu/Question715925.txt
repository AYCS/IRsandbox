[{"id":715925,"title":"&#39;gzip: file.log.gz: not in gzip format&#39; error","body":"<p>I have a <code>.gz</code> folder and I tried to unzip it using terminal by the following commands, but gave error.  </p>\n\n<pre><code>gunzip access-2.log.gz  \ngzip -d access-2.log.gz  \n</code></pre>\n\n<p><a href=\"http://i.stack.imgur.com/EhHVO.png\" rel=\"nofollow\"><img src=\"http://i.stack.imgur.com/EhHVO.png\" alt=\"gunzip\"></a>\n<a href=\"http://i.stack.imgur.com/aLzCz.png\" rel=\"nofollow\"><img src=\"http://i.stack.imgur.com/aLzCz.png\" alt=\"gzip\"></a>  </p>\n\n<p>Then I followed the error in <a href=\"http://askubuntu.com/\">Ask Ubuntu</a>, found this <a href=\"http://askubuntu.com/questions/562763/gzip-stdin-not-in-gzip-format-when-gunzip-is-used-with-pipe\">question</a><br>\nAfter that I gave the command in terminal  </p>\n\n<pre><code>gunzip Desktop/project/data/access-2.log.gz   \n</code></pre>\n\n<p>similar error.<a href=\"http://i.stack.imgur.com/dzEpG.png\" rel=\"nofollow\"><img src=\"http://i.stack.imgur.com/dzEpG.png\" alt=\"path\"></a> </p>\n\n<p>Why I'm getting this issue?<br>\nWhat is the solution to unzip the <code>name.log.gz</code> folder?</p>\n","related_questions":[{"id":693409,"title":"how can I extract multiple gzip files in directory and subdirectories?","body":"<p>I have tried both <code>gzip</code> and <code>gunzip</code> commands but I get either</p>\n\n<pre><code>gunzip *.gz \ngzip: invalid option -- 'Y' \n\ngunzip -S-1800-01-01-000000-g01.h5.gz  \ngzip: compressed data not read\n from a terminal. Use -f to force decompression. For help, type: gzip -h\n</code></pre>\n\n<p>If I try the <code>-f</code> option it takes a very long time to work on one single file and the command is not executed successfully. Am I missing something?</p>\n"},{"id":62655,"title":"&quot;less&quot; doesn&#39;t automatically decompress gzipped files","body":"<p>On Fedora/Redhat/CentOS the <code>less</code> command seems to magically detect a gzipped file and decompress it on the fly, so you can do:</p>\n\n<pre><code>less my_stuff.csv.gz\n</code></pre>\n\n<p>I've just noticed this doesn't work on Ubuntu 11</p>\n\n<pre><code>less my_stuff.csv.gz\n\"my_stuff.csv.gz\" may be a binary file.  See it anyway? \n</code></pre>\n\n<p>I've been examining my CentOS VMs to see if there's some shell alias magic that makes it work but there doesn't seem to be. Is gzip support just built in to the CentOS binary?</p>\n\n<p>If anyone knows how this works on CentOS and/or how it can be made to work on Ubuntu I'd be grateful.</p>\n\n<p>I'm aware I can do</p>\n\n<pre><code>zcat my_stuff.csv.gz | less\n</code></pre>\n\n<p>but that would make my keyboard wear out more quickly.</p>\n"},{"id":620852,"title":"Error, even with sudo: &quot;dd: failed to open ‘/dev/sda1’: Permission denied&quot; (dd input piped from gzip)","body":"<p>My command which <strong>doesn't work</strong>:<br></p>\n\n<pre><code>sudo gzip -dc sda1.image.gz | dd of=/dev/sda1\n</code></pre>\n\n<p>returns the following error even before I've had a chance to enter my password:<br></p>\n\n<pre><code>dd: failed to open ‘/dev/sda1’: Permission denied\n[sudo] password for ken:\n</code></pre>\n\n<p>I've also tried without the \"-dc\" options and get the same error.  </p>\n\n<p>However, the dd command <strong>without gzip, using an uncompressed file, does work</strong>:</p>\n\n<pre><code>sudo dd if=sda1.image of=/dev/sda1\n</code></pre>\n\n<p>It seems like the sudo is only applying to the first command and not the entire sequence of commands.  If I remain in the same terminal session and repeat the command, I don't get the password prompt (my authentication seems to persist) and yet I still get the same error (as if my authentication is not applying to the /dev write operation).  The same error occurs when executed from a /bin/sh script.<p>\nHow should I construct my command(s) to uncompress my image to the device?</p>\n\n<p>I'm using Ubuntu 14.04 LTS in a terminal window.  </p>\n"},{"id":591808,"title":"GZip of drive image created by using `dd` command","body":"<p>I created yesterday a drive image using GZip.</p>\n\n<p>I opened the 51.3 GiB file named <strong>ssd.img.gz</strong> to see one icon thats a package of 3.9 GiB, yes, thats THree point Nine Gigabytes in size and has the name of the image as <strong>ssd.img</strong></p>\n\n<p>That does not seem right to me, has the image creation worked or not?</p>\n\n<p>Yes the drives have data and an operating system on it.</p>\n\n<p>Should I have used <code>cat</code> instead? only I did and it kept on saying that it had nothing to do.</p>\n\n<p>Would using the <code>| zip</code> instead be a better option?  </p>\n\n<p>** <strong>EDIT</strong> **</p>\n\n<p>The command used was:</p>\n\n<pre><code>mark@zotac:~$ sudo -l\nEnter password:&lt;entered password to get in to root&gt;\nroot@zotac:~# dd if=/dev/sda | gzip -c &gt; \"/media/mark/Seagate External Drive/ssd.img.gz\n</code></pre>\n\n<p>the terminal spent the best part of 10 Hours at building the image, something in itself that I also found suspect, why so log when copying the files to a folder that I wanted, some 40GiB took 45 minutes...</p>\n\n<p>The source drive <code>/dev/sda</code> had no mounted partitions.   </p>\n\n<p>** <strong>EDIT</strong> **</p>\n\n<p>Just to clarify, I am trying to make an image of the drive to back up later if things go wrong with a repair, the drive itself needs to be a file on a drive as the target drive partition is using almost all of the drive, the partitions can't be resized on it without formatting it and I am not about to lose 1.4TB of data. </p>\n\n<p>So the <code>dd if=/dev/sda of=/&lt;target&gt;</code> isn't what I need, what I do need is an image of the drive that I can restore the image from to the drive should the repair go wrong.</p>\n\n<p>So what command do I use, dd or cat? Why does <code>| zip</code> keep telling me it has nothing to do when used with cat but no error or warning with <code>dd</code></p>\n"},{"id":496432,"title":"gzip all files with specific extensions","body":"<p>I'm trying to gzip all files on ubuntu that have the file extension .css, .html or .js. in a top directory and all subdirectories. I want to keep the original files and overwrite the .gz file, if already existing.</p>\n\n<p>So when I have n files, I want to keep these n files and create additional n archive files. Not just one.</p>\n\n<p>My try was to run a script that looks like this:</p>\n\n<pre><code>gzip -rkf *.css\ngzip -rkf *.html\n... one line for each file extension\n</code></pre>\n\n<p>First: I need to have one line in that script for each file extension I want to gzip. That's ok, but I hope to find a better way</p>\n\n<p>Second and more important: It does not work. Although -r should do the job, the subdirectories are unchanged. The gzip file is only created in the top directory.</p>\n\n<p>What am I missing here?</p>\n\n<p>Btw: The following is a bug in the verbose output, right? When using -k and -v option</p>\n\n<pre><code>-k, --keep        keep (don't delete) input files\n-v, --verbose     verbose mode\n</code></pre>\n\n<p>The verbose output says it replaces the file, although \"replace\" means that the original file does not exist after the replace. Anyway, THis is only the output thing.</p>\n\n<pre><code>$ ls\n  index.html      subdir1  testfile      testfile.css.gz\n  javaclass.java  subdir2  testfile.css\n$ gzip -fkv *.css\n  testfile.css:   6.6% -- replaced with testfile.css.gz\n$ ls\n  index.html      subdir1  testfile      testfile.css.gz\n  javaclass.java  subdir2  testfile.css\n</code></pre>\n"},{"id":572091,"title":"Recover Huge and Broken Gzip file","body":"<p>I have a 50.9 GB file which is a backup of my home folder on Ubuntu 12.04. I compressed this file using tar on Terminal from my sda (ext4) drive to sdb (ext4). The command I used was </p>\n\n<p><code>tar cvfz /media/2ndHDD/home.tar /home/&lt;my_username&gt;</code></p>\n\n<p>I was getting this error after the compression: </p>\n\n<p><code>tar: Exiting with failure status due to previous errors</code>. </p>\n\n<p>I repeated the compression thrice but same error I'm getting when the compression is finished. Because I'm already too exhausted of this on the third attempt (especially that it took me whole day), I just disregarded the error and was hoping it won't affect when I decompress the file.</p>\n\n<p>After that, I installed a new OS which is Ubuntu 14.04 to my sda drive. After the installation, I attempted to untar the file I compressed a while ago by using this</p>\n\n<pre><code>tar xvf home.tar\n</code></pre>\n\n<p>but I'm getting this error: </p>\n\n<pre><code>gzip: stdin: invalid compressed data--format violated\ntar: Unexpected EOF in archive\ntar: Unexpected EOF in archive\ntar: Error is not recoverable: exiting now\n</code></pre>\n\n<p>So I tried to gzip the file using </p>\n\n<p><code>gzip home.tar</code> </p>\n\n<p>and waited for almost 1 hour to finish. And after that, I decompressed it again using gzip this time. </p>\n\n<pre><code>tar -xvzf home.tar.gz\n</code></pre>\n\n<p>The process just can't finish and will stop after 15 minutes which leaves the created 'home' folder incomplete of files I'm expecting. I repeated the process over and over again but won't really finish.</p>\n\n<p>Is there any way I can recover this huge compressed file? I already tried <code>gzrecover</code> (<a href=\"http://fosshelp.blogspot.com/2013/04/howto-recover-corrupted-targz-file.html\" rel=\"nofollow\">http://fosshelp.blogspot.com/2013/04/howto-recover-corrupted-targz-file.html</a>) but always fails. Could it also be possible that I already lost my files when I attempted to convert it to gzip? I really regret why I didn't just copy the home folder uncompressed. :(</p>\n\n<p>UPDATE: Just now, I attempted to convert it back to tar by using this command </p>\n\n<p><code>gzip -d home.tar.gz</code> </p>\n\n<p>and decompressed it by running </p>\n\n<p><code>tar xvf home.tar</code> </p>\n\n<p>now I'm getting this error:</p>\n\n<pre><code>gzip: stdin: invalid compressed data--format violated\ntar: Unexpected EOF in archive\ntar: Unexpected EOF in archive\ntar: Error is not recoverable: exiting now\n</code></pre>\n\n<p>And even just listing down the files inside the tar file won't finish processing</p>\n\n<pre><code>tar -tvf home.tar\n</code></pre>\n\n<p>I will still get the same error above</p>\n\n<p>UPDATE (01/11/2015):\nI tried to run <code>strace gunzip home.tar.gz</code> and after about 15-20 minutes I was getting these:</p>\n\n<pre><code>read(3, \"\\231\\300\\2678\\242p\\206\\371\\341\\322\\352\\312\\374\\271?\\252.\\1775sC\\330|D$PF$\\10r\\362V\"..., 32768) = 32768\nwrite(4, \"\\256Y\\341\\224\\362Nn\\315\\316\\373&gt;\\31\\202\\275c\\373\\266\\265\\345\\27 R\\312\\2\\221b'6\\263\\321\\10F\"..., 32768) = 32768\nread(3, \"[\\366\\\"\\r\\265\\244\\3s\\201\\223b\\n\\267\\364\\34\\247Ej\\210tF\\22\\255B\\254\\223\\216E\\26\\242\\321\\210\"..., 32768) = 32768\nwrite(4, \"\\n1g\\201\\\\m\\231\\364\\352@\\\"%\\207\\\"Q+\\37a^!8\\226\\233\\204\\244\\v\\334&amp;i\\361\\2a\"..., 32768) = 32768\nread(3, \"\\222\\327\\351\\337(\\376\\376?\\246AzC\\371\\231\\200${V\\361\\310W9.\\3571a\\362\\357\\251\\306o\\234\"..., 32768) = 32768\nwrite(4, \"\\346\\216sH\\250\\272\\264T\\335\\356&lt;?\\377\\266\\272o{\\32\\21\\264\\367\\34\\377w\\327\\220\\324\\313\\231\\2775\\337\"..., 32768) = 32768\nread(3, \"\\266\\276\\345\\213\\277}G\\235\\355\\360\\326\\232\\244\\353Z\\\\\\215\\222g\\354\\202\\356\\351\\303G~\\210\\363b\\31\\17P\"..., 32768) = 32768\nwrite(4, \"\\326!1\\332\\213\\253\\276\\327\\222&lt;\\345\\25\\210\\366\\266\\337uSkj&gt;\\345$\\257\\225\\2q\\321^8Jk\"..., 32768) = 32768\nread(3, \"~D\\212\\373\\372\\\"\\373\\367m0\\322%\\365S\\377\\335\\331\\336\\376RB\\037727e'\\371#S\\224\\223\"..., 32768) = 26366\nread(3, \"\", 6402)                       = 0\nwrite(4, \"\\23\\320\\\"\\0059\\24\\20\\\"\\5#M\\210I\\323\\320\\363T\\220N\\321\\301\\207\\\\\\327(I\\204\\362\\371\\377\\32!\"..., 32768) = 32768\nwrite(4, \" \\6\\325\\33\\246\\324\\35\\240h\\225B\\270\\312\\207\\211\\340)\\314\\27\\17\\\"pv\\2232?\\\"0Sez\\247\"..., 14402) = 14402\nclose(3)                                = 0\nutimensat(4, NULL, {{1420884866, 686801693}, {1420818997, 36136000}}, 0) = 0\nfchown32(4, 1000, 1000)                 = 0\nfchmod(4, 0666)                         = 0\nclose(4)                                = 0\nrt_sigprocmask(SIG_BLOCK, [HUP INT PIPE TERM XCPU XFSZ], [], 8) = 0\nunlink(\"home.tar.gz\")                   = 0\nrt_sigprocmask(SIG_SETMASK, [], NULL, 8) = 0\n_llseek(0, 0, 0xbf8c86a0, SEEK_CUR)     = -1 ESPIPE (Illegal seek)\nclose(0)                                = 0\nclose(1)                                = 0\nclose(2)                                = 0\nexit_group(0)                           = ?\n+++ exited with 0 +++\n</code></pre>\n\n<p>With the output above, is it possible that I can still recover it? I just don't know where to start :(</p>\n"},{"id":492331,"title":"Tar Gzip Every n Files in a Directory","body":"<p>I have a folder with 7,491 files in it. I'd like to tar gzip these in batches of 100, e.g.</p>\n\n<pre><code>first 100 files &gt; archive1.tar.gz\nfiles 101-200 &gt; archive2.tar.gz\nfiles 201-300 &gt; archive3.tar.gz\n</code></pre>\n\n<p>Is there a way to do this via the command line?</p>\n"},{"id":424969,"title":"xoj (Xournal) files handled as gzip despite presence of correct MIME type","body":"<p>So I had to uninstall the <a href=\"https://launchpad.net/~nilarimogard/+archive/webupd8\" rel=\"nofollow\">ppa</a> <a href=\"http://www.ubuntuupdates.org/package/webupd8/precise/main/base/xournal\" rel=\"nofollow\">version</a> of <a href=\"https://sourceforge.net/projects/xournal/\" rel=\"nofollow\">Xournal</a> and build from <a href=\"http://sourceforge.net/code-snapshots/git/x/xo/xournal/code.git/xournal-code-6d4c59eb9bd2b50c661701a6c5b5fbcfc617eb17.zip\" rel=\"nofollow\">source</a> (with a <a href=\"https://sourceforge.net/p/xournal/bugs/112/?limit=10&amp;page=1#000f\" rel=\"nofollow\">modification</a>).  And now .xoj files open automatically with KDE's archive manager Ark, and are identified as being of type \"Gzip archive\" when one selects Properties from the right-click menu in Dolphin:\n<img src=\"http://i.stack.imgur.com/bes9m.png\" alt=\"xoj properties from Dolphin\"><br>\n(Before, .xoj files opened with Xournal and were correctly identified.) This state of affairs persists despite all of the following:  </p>\n\n<p>1) Copied these files that come with the source package:<br>\n - <code>xournal.xml</code> into /usr/share/mime/packages/<br>\n - <code>xournal.desktop</code> into /usr/share/applications/<br>\n - <code>x-xoj.desktop</code> into /usr/share/mimelnk/application/  </p>\n\n<p>2) added the line<br>\n   <code>application/x-xoj=xournal.desktop;</code><br>\n   to ~/.local/share/applications/mimeapps.list  </p>\n\n<p>3) added the MIME type <code>application/x-xoj</code> in the <em>File Associations</em> System Setting<br>\n   (with appropriate content):<br>\n<img src=\"http://i.stack.imgur.com/45nsg.png\" alt=\"file-associations-xoj\"><br>\n   (Note also that <code>application/x-gzip</code> specifies only the .gz extension:<br>\n<img src=\"http://i.stack.imgur.com/yH6aO.png\" alt=\"enter image description here\">.)  </p>\n\n<p>4) copied <code>xournal.xml</code> to /usr/share/mime/application<br>\n   as suggested <a href=\"https://help.ubuntu.com/community/AddingMimeTypes\" rel=\"nofollow\">here</a>  </p>\n\n<p>5) <code>sudo update-mime-database /usr/share/mime</code>  </p>\n\n<p>6) restarted the computer  </p>\n\n<p><em>edited to add:</em><br>\n7) [right-click an .xoj file] --> Open With --> Other... --> [select 'Xournal'], tick 'Remember application association for this type of file' also has no effect.<br>\n<em>end of edit</em>  </p>\n\n<p>This is on Kubuntu 12.04.<br>\nSo, what am I missing?</p>\n\n<p><em>Edited to add</em><br>\nI have discovered that the <code>file --mime-type [filename]</code> and <code>mimetype [filename]</code> commands produce different results, as in <a href=\"http://askubuntu.com/questions/279899/file-mime-type-and-mimetype-commands-returning-different-results\">this question</a>:  </p>\n\n<pre><code>archelon@ingelrayok:~/Documents/xournal$ file --mime-type 2014-02-22-Note-02-09.xoj  \n2014-02-22-Note-02-09.xoj: application/x-gzip  \narchelon@ingelrayok:~/Documents/xournal$ mimetype 2014-02-22-Note-02-09.xoj  \n2014-02-22-Note-02-09.xoj: application/x-xoj  \n</code></pre>\n\n<p>However, there is no entry for <code>application/x-gzip</code> in /etc/mime.types (from which the <code>file</code> command supposedly gets its information); and, indeed, there shouldn't be, according to the comment at the beginning of that file, which reads in part:  </p>\n\n<blockquote>\n  <p>Note: Compression schemes like \"gzip\", \"bzip\", and \"compress\" are not\n   actually \"mime-types\".  They are \"encodings\" and hence must <em>not</em> have\n   entries in this file to map their extensions.  The \"mime-type\" of an\n   encoded file refers to the type of data that has been encoded, not the\n   type of encoding.</p>\n</blockquote>\n\n<p>That comment also says that  </p>\n\n<blockquote>\n  <p>Users can add their own types if they wish by creating a \".mime.types\"\n   file in their home directory.  Definitions included there will take\n   precedence over those listed here.  </p>\n</blockquote>\n\n<p>There is at present no such file.  There are some files in my home directory (which I didn't create) that are apparently related to the output of the <code>mimetype</code> command; these include<br>\n<code>~/.local/share/mime/application/x-xoj.xml</code>,<br>\n<code>~/.local/share/mime/packages/application-x-xoj.xml</code>, and<br>\n<code>~/.local/share/mime/types</code> which contains only the text <code>application/x-xoj</code>.<br>\nIn fact the directory ~/.local/share/mime/ and everything in it have the same timestamp (22:19 last night), and were thus presumably generated by the same process.  </p>\n\n<p>After looking at the manpages for <a href=\"http://manpages.ubuntu.com/manpages/precise/man1/mimetype.1p.html\" rel=\"nofollow\">mimetype</a> and <a href=\"http://manpages.ubuntu.com/manpages/precise/man1/file.1.html\" rel=\"nofollow\">file</a>, I decided to check the environment variables <code>$XDG_DATA_HOME</code> and <code>$XDG_DATA_DIRS</code>, which apparently are used by the former but not the latter.  But I didn't know how to report the value of an environment variable, so I tried <code>cat $XDG_DATA_HOME</code>, which <em>set</em> the value (to nothing) instead of reporting it.  <em>Edited to add:  Or so I thought at first; actually it was already unset, as we shall see.</em> The correct command is <code>echo $XDG_DATA_HOME</code>, as I learned from reading about environment variables <a href=\"https://help.ubuntu.com/community/EnvironmentVariables\" rel=\"nofollow\">here</a>.  So then I discovered that <code>$XDG_DATA_DIRS</code> was set to <code>/usr/share/default:/usr/local/share/:/usr/share/</code>; the first of these doesn't exist.  I don't think that matters, but anyway I ran the commands  </p>\n\n<pre><code>XDG_DATA_HOME=$HOME/.local/share  \n</code></pre>\n\n<p>and</p>\n\n<pre><code>XDG_DATA_DIRS=/usr/local/share/:/usr/share/  \n</code></pre>\n\n<p>to accord with the <a href=\"http://standards.freedesktop.org/basedir-spec/basedir-spec-latest.html\" rel=\"nofollow\">standard</a>.  I doubt that any of this will make any difference, but I'm going to try another restart now (although I think those environment variables will be automatically reset anyway). <em>Next edit</em>: Yes, they were; in fact the variable <code>XDG_DATA_HOME</code> is now null again.  </p>\n\n<p>Anyway the bottom line seems to be that KDE is using the functionality that <code>file</code> is using, rather than that which <code>mimetype</code> is using.  If I understand things correctly, this means that it is using magic instead of MIME types.  I now suspect that magic is responsible for this whole issue.  </p>\n\n<p><em>New edit</em>  </p>\n\n<p>So the <code>file</code> <a href=\"http://manpages.ubuntu.com/manpages/precise/man1/file.1.html\" rel=\"nofollow\">manpage</a> seems to be saying that these are the baseline magic files:  </p>\n\n<blockquote>\n  <p>/usr/share/misc/magic.mgc  Default compiled list of magic.<br>\n  /usr/share/misc/magic      Directory containing default magic files.  </p>\n</blockquote>\n\n<p>(I have these; /usr/share/misc/magic is a link to the empty folder /usr/share/file/magic and /usr/share/misc/magic.mgc is a link to the file /usr/share/file/magic.mgc -- the latter is a 2.1 MB file full of gobbledygook) and the following text:</p>\n\n<blockquote>\n  <p>The information identifying these files </p>\n</blockquote>\n\n<p>(i.e. \"files [which] have a ``magic number'' stored in a particular place near the beginning of the file\")  </p>\n\n<blockquote>\n  <p>is read from /etc/magic and the compiled magic file<br>\n   /usr/share/misc/magic.mgc, or the files in the directory<br>\n   /usr/share/misc/magic if the compiled file does not exist.  In addition,<br>\n   if $HOME/.magic.mgc or $HOME/.magic exists, it will be used in preference<br>\n   to the system magic files.  </p>\n</blockquote>\n\n<p>(I have confirmed this with <code>strace</code>, as suggested <a href=\"http://askubuntu.com/a/105658/192986\">here</a>.)  Neither $HOME/.magic.mgc nor $HOME/.magic exists on my system; but, since presumably xoj files contain precisely that gobbledygook which causes a file to be magically identified as <code>application/x-gzip</code>, it would do no good to create them (please correct me if I am wrong).</p>\n\n<p>The solution I'm looking for, then, would be a way to have the MIME-type specification override magic for a given file extension; I thought I had seen something that looked like it might provide a hint as to how that might be accomplished, but I can't find it now.  Yet surely such a method exists.</p>\n"},{"id":138374,"title":"internal gzip read error","body":"<p>I have a Dell Optiplex 755 Core 2 Duo that I made a fresh install of 12.04. There is no Winows OS on the machine. It has been running mostly fine for over a week. I do keep getting system crashes due to an xserver-xorg-intel conflict, but at least I know the source of that. Recently, running upgrade &amp;&amp; update I keep getting a conflict, seemingly with just one update, the most recent <code>linux-libc-dev</code>. Here's what I get:</p>\n\n<pre>\njay@jay-jay:/$ sudo apt-get upgrade && sudo apt-get update\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nThe following packages will be upgraded:\n  linux-libc-dev\n1 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.\nNeed to get 0 B/828 kB of archives.\nAfter this operation, 0 B of additional disk space will be used.\nDo you want to continue [Y/n]? y\n(Reading database ... 208582 files and directories currently installed.)\nPreparing to replace linux-libc-dev 3.2.0-23.36 (using .../linux-libc-dev_3.2.0-24.37_i386.deb) ...\nUnpacking replacement linux-libc-dev ...\ndpkg-deb (subprocess): data: internal gzip read error: ': data error'\ndpkg-deb: error: subprocess  returned error exit status 2\ndpkg: error processing /var/cache/apt/archives/linux-libc-dev_3.2.0-24.37_i386.deb (--unpack):\n subprocess dpkg-deb --fsys-tarfile returned error exit status 2\nNo apport report written because the error message indicates an issue on the local system\n         Errors were encountered while processing:\n /var/cache/apt/archives/linux-libc-dev_3.2.0-24.37_i386.deb\nE: Sub-process /usr/bin/dpkg returned an error code (1)\n\n</pre>\n\n<p>I have searched AskUbuntu, have found similar questions and have tried the accepted answers where I thought they may have been of use. At this point, I am stalled.</p>\n"},{"id":26506,"title":"Repair gzipped tar","body":"<p>I have a pretty large(50Gb) tar.gz file that I can't untar anymore. Error that I am getting is this:</p>\n\n<pre><code>gzip: stdin: not in gzip format\ntar: Child returned status 1\ntar: Error is not recoverable: exiting now\n</code></pre>\n\n<p>Is there any way to repair broken tar.gz?</p>\n\n<p>UPDATE: Output of file command:</p>\n\n<pre><code>$ file projects.tgz \nprojects.tgz: POSIX tar archive (GNU)\n</code></pre>\n"}]}]
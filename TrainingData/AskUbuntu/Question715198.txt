[{"id":715198,"title":"How recursive copy folder to s3","body":"<p>I need copy the folder to aws s3. I use command:</p>\n\n<pre><code>aws s3 cp home/user/testdir $s3_path --recursive`\n</code></pre>\n\n<p>all my files in folder <code>testdir</code> are successfully copied to s3 but subfolders like <code>testdir/dir1/  testdir/dir2/ testdir/dir3/</code> - dont copy.</p>\n","related_questions":[{"id":192050,"title":"How to run sudo command with no password?","body":"<p><strong>How does the <code>ubuntu</code> user on the AWS images for Ubuntu Server 12.04 have passwordless <code>sudo</code> for all commands when there is no configuration for it in <code>/etc/sudoers</code>?</strong></p>\n\n<p>I'm using Ubuntu server 12.04 on Amazon. I want to add a new user that has the same behavior as the default Ubuntu user. Specifically I want passwordless <code>sudo</code> for this new user. </p>\n\n<p>So I've added a new user and went to edit <code>/etc/sudoers</code> (using visudo of course). From reading that file it seemed like the default <code>ubuntu</code> user was getting it's passwordless <code>sudo</code> from being a member of the <code>admin</code> group. So I added my new user to that. Which didn't work. Then I tried adding the <code>NOPASSWD</code> directive to <code>sudoers</code>. Which also didn't work. </p>\n\n<p>Anyway, now I'm just curious. How does the <code>ubuntu</code> user get passwordless privileges if they aren't defined in <code>/etc/sudoers</code>. What is the mechanism that allows this?</p>\n"},{"id":165323,"title":"I would like to set up a ubuntu OS on Amazon web server, how do I do this","body":"<p>I am trying to set up a virtual OS (ubuntu, windows) on amazon web services to run apps 24/7 and to have anytime I log in on the internet. Is this a possibility to do and if so how?</p>\n"},{"id":632141,"title":"Find and Rename recursively in folders, subfolders and multiple files","body":"<p>I'm new with shellscript and I'm having some problems trying to do what I need... </p>\n\n<p>I want to 'optimize' all my *.png images and found <a href=\"http://es.kioskea.net/faq/7287-reducir-el-tamano-de-imagenes-png\" rel=\"nofollow\">this</a> so I made the bash  as it says with:</p>\n\n<pre><code>#!/bin/bash    \n pngnq -vf -s1 *.png    \n rename -nq8.png .png *-nq8*     \n optipng -o7 *.png\n</code></pre>\n\n<p>What this do is: </p>\n\n<ul>\n<li><code>pngnq -vf -s1 *.png</code> takes a *png ofr example Image.png and craetes a copy named Image-nq8.png which is the one optimized    </li>\n<li><code>rename -nq8.png .png *-nq8*</code>makes Image-nq8.png become Image.png so you have the same as before but optimized (so you can have the same in the folders as you had before optimize) &lt;= VERY IMPORTANT!     </li>\n<li><code>optipng -o7 *.png</code> does another optimization to Images.png without making any copy.</li>\n</ul>\n\n<p>But now I have a problem:</p>\n\n<p>If I write in console every line in order, it works ok on the folder I am but now I need to do it automatically and recursive. I explain my case:</p>\n\n<p>note:  I say folder as a directory </p>\n\n<p>I have a folder named ImagesFolder and inside I have other folders with more *.pngs and I want to run this bash in every subfolder of ImagesFolder but I don't know how to do it (as I said I'm new in unix and shellscripts and so on) and what I found on internet and tried didn't work or was a completly mess...</p>\n\n<p>To understand it better what I have is something like:</p>\n\n<pre><code>ImagesFolder\n  |-Folder1\n  |     |- Folder12\n  |     |      |-20 images here\n  |     |- Folder13\n  |     |      |- 10 images more here\n  |     |-  _Folder &lt;- I have some folder names that start with '_'\n  |     |- 5 images here \n  |-more images and folders and subfoldrs\n</code></pre>\n\n<p>This is the structure and I want the script to run from ImagesFolder.</p>\n\n<p>I tried with a for and a find in it, and with a find in console calling the script... tried too appling some examples I found here in stack but nothing... Probably is because as I don't really know how does this work I can't apply it just like that. Hope you can help me with this problem.</p>\n\n<p>Thank you so much!</p>\n\n<p>Edit: To run the script I have to go to ImageFolder, open a console and put <code>chmod u+x name_of_my_script</code> could this be a problem to run it into the subfolders? If yes, can you tell me how to fix it? </p>\n"},{"id":606528,"title":"Copy pictures recursively from one folder to the root of another?","body":"<p>So, I have a Windows virtual machine running this certain program. The details are as follows:</p>\n\n<ol>\n<li>The program has no recursive search functionality.</li>\n<li>I have lots of free disk space.</li>\n<li>I have excess junk in my pictures folder. (I just want to copy the pictures, assume I have pictures ranging every known picture file extension (excluding archives))</li>\n<li>I want to use the command line to scan for every picture in my home directory recursively, and copy all of them to the current directory WITHOUT creating sub folders that match my pictures folder. (Ex: <code>~/cyndaquil.png</code> is copied to <code>./cyndaquil.png</code>, while <code>~/foo/bar/quilava.png</code> is copies to <code>./quilava.png</code>. Also, my home directory is a mess.)</li>\n</ol>\n\n<p>So, is there any command I can use to do this?</p>\n"},{"id":592805,"title":"Why does cp not copy a specified folder","body":"<p>let's say that I have a following file structure:</p>\n\n<pre><code>~/DIR1\n-fileA\n-DIR2\n--fileB\n</code></pre>\n\n<p>Then, being in ~, I run this script:</p>\n\n<pre><code>cp DIR1 NEWDIR2\n</code></pre>\n\n<p>And just an error happens:</p>\n\n<pre><code>cp: omitting directory ‘DIR1’\n</code></pre>\n\n<p>I understand why nothing from DIR1 gets copied (because I didn't use -r switch that would enforce recursion) but I'd expect the DIR1 folder itself copied to NEWDIR2 (so practically a creation of a new \"NEWDIR2\" in ~ or a creation of ~/NEWDIR2/DIR1).</p>\n\n<p>Could someone explain to me why is my expectation wrong?</p>\n"},{"id":429791,"title":"How To Set FQDN From Bash Script","body":"<p>Is it possible to set the fully qualified domain name from a bash script?</p>\n\n<p>I am using Ubuntu 12.04 LTS. I have an autoscaling group on Amazon and I am using Puppet for configuration.</p>\n\n<p>For example, I would like to use admin.staging.mycompany.net as a FQDN for all instances in the autoscaling group. I can run a bash script when the autoscaling group fires new instances.</p>\n\n<p>Since Puppet uses the fully qualified domain name to figure out which manifest to apply, I need to come up with a way to set a new EC2 instance's FQDN from a bash script, so the autoscaling group can fire up a new instance and apply the correct Puppet manifest.</p>\n\n<p>I don't want to ssh to instances and manually change /etc/hosts and /etc/hostname as that would defeat the point of the autoscaling group.</p>\n"},{"id":268025,"title":"Copying from mount share drive to local folder through script","body":"<p>This is my first time trying to work with Linux Scripts so this may be something obvious.</p>\n\n<p>Here is what I am trying to do:</p>\n\n<ol>\n<li>Remove all contents from local folder - rm /home/user/Documents/Exercise/</li>\n<li>Copy files from a shared windows network drive - cp smb://server/arc/Exercise%20Files/Word/</li>\n</ol>\n\n<p>So from my understanding my command should look like this</p>\n\n<pre><code>  rm /home/user/Documents/Exercise/\n  cp smb://server/arc/Exercise%20Files/Word/ /home/user/Documents/Exercise/\n</code></pre>\n\n<p>But anytime I try and run either of the above commands I get the following error:</p>\n\n<pre><code>  \"rm: cannot remove `/home/user/Documents/Exercise/': Is a directory\"\n  \"cp: cannot stat `smb://server/arc/Exercise%20Files/Word/': No such file or directory\"\n</code></pre>\n\n<p>What am I doing wrong?</p>\n\n<p>Kind Regards,</p>\n\n<p>M</p>\n\n<p>EDIT:</p>\n\n<p>I now have the <code>rm</code> function working yet am still troubled by the <code>cp</code> function. To ensure it is not an issue with the spaces in the folder names I have renamed the folders on the share so it now reads:\n<code>//server/Arc/ExerciseFiles/*</code></p>\n\n<p>I have mounted the folder so I (assume) no longer need the <code>smb://</code>. It currently reads:\n<code>cp -rfv /home/user/Documents/ExerciseShare/ExerciseFiles/Word/ /home/user/Documents/Exercise/</code></p>\n\n<p>M</p>\n"},{"id":167160,"title":"How can I recursively check folders with flac files for corruption?","body":"<p>Something caused to damage some of my flac files, and to find out which ones I need to rerip, I would like to get a list containing only the damaged files.</p>\n\n<p>How I do it now: Open a terminal in a directory, and enter: $ flac -t *.flac</p>\n\n<p>The output of good files is something like:</p>\n\n<pre><code>Song1.flac: ok\nSong2.flac: ok\n</code></pre>\n\n<p>On some of my old rips I get warnings, but the song seems to be okay:</p>\n\n<pre><code>Song3.flac: WARNING, cannot check MD5 signature since it was unset in the STREAMINFO\nSong3.flac: ok \n</code></pre>\n\n<p>But when an error occurs, the messages are something like:</p>\n\n<pre><code>Song4.flac: testing, 73% complete\nSong4.flac: ERROR while decoding data\n             state = FLAC__STREAM_DECODER_END_OF_STREAM\nSong5.flac: ERROR while decoding data\n            state = FLAC__STREAM_DECODER_READ_FRAME\nSong6.flac: ERROR, MD5 signature mismatch                                          \nSong7.flac: *** Got error code 3:FLAC__STREAM_DECODER_ERROR_STATUS_UNPARSEABLE_STREAM\nSong7.flac: *** Got error code 0:FLAC__STREAM_DECODER_ERROR_STATUS_LOST_SYNC\n\nSong7.flac: ERROR while decoding data\n            state = FLAC__STREAM_DECODER_READ_FRAME\n\nThe FLAC stream may have been created by a more advanced encoder.  Try\n  metaflac --show-vendor-tag Song7.flac\nIf the version number is greater than 1.2.1, this decoder is probably\nnot able to decode the file.  If the version number is not, the file\nmay be corrupted, or you may have found a bug.  In this case please\nsubmit a bug report to\n    http://sourceforge.net/bugs/?func=addbug&amp;group_id=13478\nMake sure to use the \"Monitor\" feature to monitor the bug status.\n</code></pre>\n\n<p>My question is:</p>\n\n<ul>\n<li>How can I filter the output to only show files with warnings (output contains WARNING) or errors (output contains ERROR)?</li>\n</ul>\n\n<p>I think it might be doable with grep, but I don't know how to give the output of the flac -t command to grep. With flac -c </p>\n\n<ul>\n<li>And if that works, how can I check all subdirs at once?</li>\n</ul>\n\n<p>My music collection is sorted into many subdirs and going to every dir and run the command would be laborious.</p>\n\n<p>Bonus points if it could output the path of the corrupt file, not only the name :)</p>\n"},{"id":74251,"title":"Add user to an AWS instance","body":"<p>I'd like to add a user to my AWS instance and ssh in as that user with the existing keypair.</p>\n\n<p>Right now I can log into my AWS instance as root:</p>\n\n<pre><code>ssh -i ~/path/mysshkeypair.pem root@EC2-my###-###.compute-1.amazonaws.com\n</code></pre>\n\n<p>Logged in as root, I created another user and gave it a home directory. I can type \"su otheruser\" and navigate around. But when I exit back to my machine and try:</p>\n\n<pre><code>ssh -i ~/path/mysshkeypair.pem otheruser@EC2-my###-###.compute-1.amazonaws.com\n</code></pre>\n\n<p>I get:\nPermission denied (publickey).</p>\n\n<p>What steps do I need to follow to be able to log in as otheruser? </p>\n\n<p>My machine is a Mac and the instance is an Ubuntu machine. </p>\n"},{"id":51720,"title":"How to open TCP port 7777 in control panel?","body":"<p>I am initiating file transfer using tcp on openfire server. But I am not able to open the port number 7777, from which I need to send files. I changed the security setting in the admin console panel of the aws. But still when I tried to send the files I am getting the error.</p>\n\n<p>I tried to change the custom TCP rules, by opening only the 7777 port. But still I am not able to resolve it. Kindly help.</p>\n"}]}]